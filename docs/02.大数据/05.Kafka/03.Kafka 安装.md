---
title: Kafka 安装
date: 2022-03-17 22:08:02
permalink: /pages/6bd0d7/
categories:
  - 大数据
  - Kafka
tags:
  - 
---
# Kafka 安装

Kafka 不依赖于hadoop运作  **只依赖zookeeper运行**

要先事先安装好zookeeper 并运行  

http://kafka.apache.org/downloads

```sh
tar -zxvf kafka_2.11-2.4.1.tgz -C /opt/module/
cd /opt/module/
mv kafka_2.11-2.4.1/ kafka
cd kafka
mkdir logs

#环境变量
sudo vim /etc/profile.d/my_env.sh

#KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin

source /etc/profile.d/my_env.sh
```

配置kafka

```sh
vim /opt/module/kafka/config/server.properties
```

```properties
#broker的全局唯一编号，不能重复
broker.id=0
#删除topic功能使能
delete.topic.enable=true

#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘IO的现成数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600

#kafka运行日志存放的路径
log.dirs=/opt/module/kafka/logs

#topic在当前broker上的分区个数
num.partitions=1
#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment文件保留的最长时间，超时将被删除
log.retention.hours=168

#配置连接Zookeeper集群地址
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
```

分发环境变量和kafka

```sh
sudo xsync /opt/module/kafka 
sudo xsync /etc/profile.d/my_env.sh
```

修改每个kafka中 broker.id

```sh
vim /opt/module/kafka/config/server.properties
#102 为 2, 103为3  , 104为4
```

启动

```sh
kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties #每台机器单独起

kafka-server-stop.sh #关闭
```

群起脚本  **记得先启动zookeeper**

```sh
sudo vim /bin/kafkalist.sh

for i in `cat /opt/module/hadoop-3.1.3/etc/hadoop/workers`
do
echo "========== $i ==========" 
ssh $i 'kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties'
echo $?
done


sudo chmod +x /bin/kafkalist.sh
```

如果遇kafka闪退 可以尝试删除logs文件夹下的内容

查看zookeeper中是否有kafka id已经记录

```sh
zkCli.sh
ls /kafka/brokers/ids
```



