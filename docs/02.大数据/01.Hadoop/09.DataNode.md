---
title: DataNode
date: 2022-05-02 16:18:40
permalink: /pages/4bc7cf/
categories:
  - 大数据
  - Hadoop
tags:
  - 
---
# DataNode

![image-20210902093056464](https://cdn.jsdelivr.net/gh/Iekrwh/images/md-images/image-20210902093056464-16305462634723.png)



## 数据完整性

奇偶校验位 如果传输数据1为偶数个数则为0  如果为奇数个1则为1   

如果原始数据与接收数据发生改变又恰好奇偶性一致 则这个现象我们称为校验碰撞

crc校验位  32位

md5 128位

sha1 160位

![image-20210902094110493](https://cdn.jsdelivr.net/gh/Iekrwh/images/md-images/image-20210902094110493.png)



## 扩展集群

服役新数据节点

1. 克隆 修改主机名 ip 

2. ```sh
   #复制module文件夹 在其他集群中复制  和环境变量
   sudo rsync -av /opt/module hadoop105:/opt
   sudo rsync -av /etc/profile.d hadoop105:/etc
   ```

3. ```sh
   #在扩展机中删除logs data 文件夹
   cd /opt/module/hadoop-3.1.3/
   rm -rf data logs
   source /etc/profile
   hadoop version
   ```

4. ```sh
   hdfs --daemon start datanode 
   yarn --daemon start nodemanager  
   jps
   ```

此方式是手动启动 如果想要群启动则需要配置免密登陆

```sh
#在102中配置
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers 
```

追加上地址

```sh
hadoop105
```

同步所有集群

```sh
xsync /opt/module/hadoop-3.1.3/etc/hadoop/workers 
```



### 添加黑/白名单

在hadoop文件夹下 新建balcklist和whitelist

```sh
#主机上写 102
cd /opt/module/hadoop-3.1.3/etc/hadoop
touch balcklist
touch whitelist
```

添加白名单  一般whitelist内容和workers相同

```sh
vim whitelist
```

```sh
hadoop102
hadoop103
hadoop104
hadoop105
```

再编辑hdfs-size.xml

```sh
vim hdfs-site.xml 
```

添加以下内容

```xml
<property>
<name>dfs.hosts.exclude</name>
      <value>/opt/module/hadoop-3.1.3/etc/hadoop/balcklist</value>
</property>
<property>
<name>dfs.hosts</name>
      <value>/opt/module/hadoop-3.1.3/etc/hadoop/whitelist</value>
</property>
```

重启集群

```sh
stop-dfs.sh
```

开启

```sh
start-dfs.sh
```



### 黑名单退役

编辑 balcklist 添加黑名单地址

```sh
vim balcklist
hdfs dfsadmin -refreshNodes  #刷新节点
```

退役的机器 自动上传文件到服役中的其他主机中

关闭节点

```sh
hdfs --daemon stop datanode
```





## DateNode 多目录配置

DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本

```sh
vim hdfs-site.xml
```

多个目录之间逗号隔开

```sh
<property>
        <name>dfs.datanode.data.dir</name>
<value>file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2</value>
</property>
```

配置完成后重启

```sh
hdfs --daemon stop datanode
hdfs --daemon start datanode
```



