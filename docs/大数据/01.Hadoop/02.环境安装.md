---
title: 环境安装
date: 2022-03-17 21:41:51
permalink: /pages/083fca/
categories:
  - Hadoop
tags:
  - 
---
# 环境安装

 https://hadoop.apache.org/docs/stable/  官方文档

## 虚拟机安装前置

```sh
sudo yum install -y epel-release  #额外软件源
sudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git wget #安装 psmisc工具包  nc工具包 net-tools工具包 rsync 远程同步  vim编辑器 lrzsz上传下载  ntp时间同步 
```

## 修改静态地址

```sh
sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33
#如手写可以 ctrl+alt+tab 补全  
```

配置为符合的  记得改UUID和Mac地址

```sh
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.1.101
PREFIX=24
GATEWAY=192.168.1.2
DNS1=192.168.1.2
```

```sh
service network restart
```

## 修改主机名

```sh
sudo hostnamectl --static set-hostname hadoop102
```

## 修改hosts

```sh
sudo vim /etc/hosts
```

```sh
192.168.1.100 hadoop100
192.168.1.101 hadoop101
192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104
192.168.1.105 hadoop105
192.168.1.106 hadoop106
192.168.1.107 hadoop107
192.168.1.108 hadoop108
```

物理机也改host



## 关闭防火墙

```sh
sudo systemctl stop firewalld
sudo systemctl disable firewalld
```



## 创建用户

```sh
sudo useradd atguigu
sudo passwd atguigu

reboot
```



## 修改atguigu权限

```sh
visudo
```



```sh
#第91行
## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
atguigu   ALL=(ALL)     ALL
```

创建opt下的存放目录

```sh
cd /opt
sudo mkdir module
sudo mkdir software
sudo chown atguigu:atguigu /opt/module /opt/software
```



## 安装java

先卸载

```sh
rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
```

解压

```sh
cd /opt/software/
tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
```

配置环境变量

```sh
sudo vim /etc/profile.d/my_env.sh
```



```sh
#JAVA_HOME
#yum 为/usr/lib/jvm/java
export JAVA_HOME=/opt/module/jdk1.8.0_212 
export PATH=$PATH:$JAVA_HOME/bin
```

更新环境变量

```sh
source /etc/profile
java -version
```



## 安装hadoop

解压

```sh
tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
```

配置环境变量

```sh
sudo vim /etc/profile.d/my_env.sh
```



```sh
##HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

更新

```sh
source /etc/profile
hadoop version
```



## SSH免密登陆

生成密钥  全部回车 为空即可

```
ssh-keygen -t rsa
```

发送密钥 给另外一台主机

```sh
ssh-copy-id hadoop102

ssh-copy-id hadoop103

ssh-copy-id hadoop104
```

默认存储在 /home/用户/.ssh文件下

**注意**：

还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；

还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。

### xsync 脚本



安装

```sh
yum install -y rsync
```

创建xsync脚本

```sh
cd /home/atguigu
vim xsync
```



```sh
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #6. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done
```



```sh
chmod +x xsync
sudo mv xsync /bin/   #将脚本移动到/bin中，以便全局调用
```

https://rsync.samba.org/

https://vault.centos.org/6.5/os/x86_64/

安装包安装

```sh
wget https://vault.centos.org/6.5/os/x86_64/Packages/rsync-3.0.6-9.el6_4.1.x86_64.rpm
rpm -ivh rsync-3.0.6-9.el6_4.1.x86_64.rpm
```





### 复制ssh免密key

```sh
cd /home/atguigu
xsync .ssh
```



### 同步环境

同步环境变量

```sh
sudo xsync /etc/profile.d/my_env.sh
```

同步软件

```sh
cd /
sxsync opt
```



## hadoop配置文件

```sh
cd /opt/module/hadoop-3.1.3/etc/hadoop
```

### 配置core-site.xml  

```sh
vim core-site.xml 
```

在`<configuration>`标签中追加

```xml
<property>
        <name>fs.defaultFS</name>
    <!-- 配置hdfs默认的地址 -->
        <value>hdfs://hadoop102:8020</value>
    </property>
    <property>
        <!-- 配置hadoop临时存放路径-->
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
    <property>
        <!-- 兼容性配置hive -->
        <name>hadoop.proxyuser.atguigu.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.atguigu.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
    </property>
```

### 配置hdfs-site.xml

```sh
vim hdfs-site.xml
```

同样在`<configuration>`标签中追加

```xml
<property>
    <!-- 2nn的地址 -->
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
```

### 配置yarn-site.xml

```sh
vim yarn-site.xml
```

同样在`<configuration>`标签中追加

```xml
<property>
    <!--设置NodeManager上运行的附属服务，需配置成mapreduce_shuffle才可运行MapReduce程序-->
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
	<!--设定单个容器可以申领到的最小内存资源-->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>2048</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>4096</value>
    </property>
<!--设定物理节点有4G内存加入资源池-->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>

```

### 配置mapred-site.xml

```sh
vim mapred-site.xml
```

同样在`<configuration>`标签中追加

```xml
<!--Hadoop对MapReduce运行框架一共提供了3种实现，在mapred-site.xml中通过"mapreduce.framework.name"这个属性来设置为"classic"、"yarn"或者"local"-->
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
```



### 配置**workers**

```sh
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
```

删除localhost  文件中添加的内容结尾不允许有空格，文件中不允许有空行。

```sh
hadoop102
hadoop103
hadoop104
```



### 同步

```sh
cd ..
xsync hadoop
```



## 启动集群

格式化hdfs

```sh
hdfs namenode -format  #在节点机子上
```

启动集群

```sh
start-dfs.sh
```

如果报java未找到 修改hadoop.env.sh文件

```sh
vim /opt/module/hadoop-3.1.3/etc/hadoop/hadoop.env.sh
```

修改JAVA_HOME为 并同步

```sh
export JAVA_HOME=/usr/lib/jvm/java
```

![image-20210831074812487](https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210831074812487.png)

显示这样启动成功



### dfs启动

在103中启动

```sh
start-yarn.sh
```



### JPS

```sh
JPS
```



## 配置历史服务器

关闭dfs和yarn

```sh
stop-yarn.sh  #103
stop-dfs.sh  #102
```



### **配置mapred-site.xml**

```sh
vi mapred-site.xml
```

同样在`<configuration>`标签中追加

```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```



## 配置日志聚集

### 配置 yarn-site.xml

```sh
vim yarn-site.xml
```

同样在`<configuration>`标签中追加

```xml
<property>
    <!-- 开启日志聚集-->
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<property>  
    <!-- 日志服务器-->
    <name>yarn.log.server.url</name>  
    <value>http://${yarn.timeline-service.webapp.address}/applicationhistory/logs</value>
</property>
<property>
    <!-- 日志保存时间-->
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
<property>
    <name>yarn.timeline-service.enabled</name>
    <value>true</value>
</property>
<property>
    <name>yarn.timeline-service.hostname</name>
    <value>${yarn.resourcemanager.hostname}</value>
</property>
<property>
    <name>yarn.timeline-service.http-cross-origin.enabled</name>
    <value>true</value>
</property>
<property>
    <name>yarn.resourcemanager.system-metrics-publisher.enabled</name>
    <value>true</value>
</property>
```



## 配置完成重新同步 并启动

```sh
cd ..
xsync hadoop/
```

重新启动

```sh
start-dfs.sh  #102

start-yarn.sh  #103

mapred --daemon start historyserver  #102 启动历史服务器
```

配置完成后**不要同步整个hadoop文件夹**  只需要etc配置文件夹  千万不要同步data文件夹

如想修改data路径

```sh
vim /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml  #hadoop.data.dir
```

如果想重新按配置开 删除掉logs文件夹里的东西 重新格式化HDFS 再启动 



## 集群时间同步

在所有节点关闭ntp服务和自启动  

建议root用户下操作

```sh
su -
sudo systemctl stop ntpd
sudo systemctl disable ntpd
```

### 修改ntp配置文件

```sh
vim /etc/ntp.conf
```



```sh
restrict 192.168.130.2 mask 255.255.255.0 nomodify notrap  #去掉#号修改即可

#加上井号
#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst

#添加
server 127.127.1.0
fudge 127.127.1.0 stratum 10
```



### 修改ntpd文件

```sh
vim /etc/sysconfig/ntpd
```



```sh
#追加
SYNC_HWCLOCK=yes
```





```sh
#重启服务
systemctl start ntpd

#开机启动
systemctl enable ntpd
```

以上修改文件在102进行



### 其他机器配置

切换root用户 进行

```sh
su -
crontab -e
```



```sh
#追加
*/1 * * * * /usr/sbin/ntpdate hadoop102
```



```SH
date  #查看当前时间是否同步
```

## 常用端口

### hadopp2.x和3.x端口变化

| hadoop2.x          | Hadoop3.x |       |
| ------------------ | --------- | ----- |
| 访问HDFS端口       | 50070     | 9870  |
| 访问MR执行情况端口 | 8088      | 8088  |
| 历史服务器         | 19888     | 19888 |
| 客户端访问集群端口 | 9000      | 8020  |

![image-20211205001142660](https://gitee.com/Iekrwh/md-images/raw/master/images/image-20211205001142660.png)

### HDFS

| 组件 | 节点        | 端口 | 配置                         | 用途说明                                                |
| ---- | ----------- | ---- | ---------------------------- | ------------------------------------------------------- |
| HDFS | Namenode    | 9870 | dfs.namenode.http-address    | http服务的端口                                          |
| HDFS | NameNode    | 9871 | dfs.namenode.https-address   | https服务的端口                                         |
| HDFS | NameNode    | 9820 | fs.defaultFS                 | 接收Client连接的RPC端口，用于获取文件系统metadata信息。 |
| HDFS | DataNode    | 9866 | dfs.datanode.address         | datanode服务端口，用于数据传输                          |
| HDFS | DataNode    | 9864 | dfs.datanode.http.address    | http服务的端口                                          |
| HDFS | DataNode    | 9865 | dfs.datanode.https.address   | https服务的端口                                         |
| HDFS | DataNode    | 9867 | dfs.datanode.ipc.address     | ipc服务的端口                                           |
| HDFS | journalnode | 8485 | dfs.journalnode.rpc-address  | RPC服务                                                 |
| HDFS | journalnode | 8480 | dfs.journalnode.http-address | HTTP服务                                                |



### Yarn

| 组件 | 节点              | 端口  | 配置                                          | 用途说明                          |
| ---- | ----------------- | ----- | --------------------------------------------- | --------------------------------- |
| YARN | ResourceManager   | 8032  | yarn.resourcemanager.address                  | RM的applications manager(ASM)端口 |
| YARN | ResourceManager   | 8030  | yarn.resourcemanager.scheduler.address        | scheduler组件的IPC端口            |
| YARN | ResourceManager   | 8031  | yarn.resourcemanager.resource-tracker.address | IPC                               |
| YARN | ResourceManager   | 8033  | yarn.resourcemanager.admin.address            | IPC                               |
| YARN | ResourceManager   | 8088  | yarn.resourcemanager.webapp.address           | http服务端口                      |
| YARN | NodeManager       | 8040  | yarn.nodemanager.localizer.address            | localizer IPC                     |
| YARN | NodeManager       | 8042  | yarn.nodemanager.webapp.address               | http服务端口                      |
| YARN | NodeManager       | 8041  | yarn.nodemanager.address                      | NM中container manager的端口       |
| YARN | JobHistory Server | 10020 | mapreduce.jobhistory.address                  | IPC                               |
| YARN | JobHistory Server | 19888 | mapreduce.jobhistory.webapp.address           | http服务端口                      |



### Hbase

| 组件  | 节点         | 端口  | 配置                                | 用途说明                                                     |
| ----- | ------------ | ----- | ----------------------------------- | ------------------------------------------------------------ |
| HBase | Master       | 60000 | hbase.master.port                   | IPC                                                          |
| HBase | Master       | 60010 | hbase.master.info.port              | http服务端口                                                 |
| HBase | RegionServer | 60020 | hbase.regionserver.port             | IPC                                                          |
| HBase | RegionServer | 60030 | hbase.regionserver.info.port        | http服务端口                                                 |
| HBase | HQuorumPeer  | 2181  | hbase.zookeeper.property.clientPort | HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 |
| HBase | HQuorumPeer  | 2888  | hbase.zookeeper.peerport            | HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 |
| HBase | HQuorumPeer  | 3888  | hbase.zookeeper.leaderport          | HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 |

### Hive

| 组件 | 节点       | 端口  | 配置                                                         | 用途说明 |
| ---- | ---------- | ----- | ------------------------------------------------------------ | -------- |
| Hive | Metastore  | 9083  | /etc/default/hive-metastore中export PORT=`<port>`来更新默认端口 |          |
| Hive | HiveServer | 10000 | /etc/hive/conf/hive-env.sh中export HIVE_SERVER2_THRIFT_PORT=`<port>`来更新默认端口 |          |

### Zookeeper

| 组件      | 节点   | 端口 | 配置                                                         | 用途说明                                                |
| --------- | ------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------- |
| ZooKeeper | Server | 2181 | /etc/zookeeper/conf/zoo.cfg中clientPort=`<port>`               | 对客户端提供服务的端口                                  |
| ZooKeeper | Server | 2888 | /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分 | follower用来连接到leader，只在leader上监听该端口。      |
| ZooKeeper | Server | 3888 | /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分 | 用于leader选举的。只在electionAlg是1,2或3(默认)时需要。 |

