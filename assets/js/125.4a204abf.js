(window.webpackJsonp=window.webpackJsonp||[]).push([[125],{455:function(s,t,a){"use strict";a.r(t);var n=a(3),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"scrapy"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scrapy"}},[s._v("#")]),s._v(" Scrapy")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Iekrwh/images/md-images/image-20220422210729657.png",alt:"image-20220422210729657"}})]),s._v(" "),t("h2",{attrs:{id:"创建项目"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#创建项目"}},[s._v("#")]),s._v(" 创建项目")]),s._v(" "),t("p",[t("strong",[s._v("初始化项目")])]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("scrapy startproject 项目名称\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("创建爬虫")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#scrapy genspider 项目名 爬取的url域名/地址")]),s._v("\nscrapy genspider dfcf “http"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("eastmoney"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("zjlx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("detail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("html”\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[t("strong",[s._v("项目名")]),s._v("：作为爬虫运行时的参数")]),s._v(" "),t("p",[t("strong",[s._v("爬取的域名/地址")]),s._v("：对爬虫设置的爬取范围，设置之后用于过滤要爬取的url，如果爬取的url与允许的域不同则会被过滤掉。")]),s._v(" "),t("p",[t("strong",[s._v("项目结构")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("整个工程的目录结构如下：\n├── scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cfg "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#工程信息")]),s._v("\n└── xy3\n├── __init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py\n├── items"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#需要解析出来的内容")]),s._v("\n├── pipelines"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#处理解析出来的items")]),s._v("\n├── settings"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#爬虫的设置内容")]),s._v("\n└── spiders\n├── dhxy3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#解析内容，生成新的请求规则的蜘蛛")]),s._v("\n└── __init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("py\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("ul",[t("li",[s._v("scrapy.cfg: 项目的配置文件。")]),s._v(" "),t("li",[s._v("mySpider/: 项目的Python模块，将会从这里引用代码。")]),s._v(" "),t("li",[s._v("mySpider/items.py: 项目的目标文件。")]),s._v(" "),t("li",[s._v("mySpider/pipelines.py: 项目的管道文件。")]),s._v(" "),t("li",[s._v("mySpider/settings.py: 项目的设置文件。")]),s._v(" "),t("li",[s._v("mySpider/spiders/: 存储爬虫代码目录。")])]),s._v(" "),t("p",[t("strong",[s._v("运行项目")])]),s._v(" "),t("p",[s._v("在项目文件以命令行形式运行")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" tutorial\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#scrapy crawl 爬虫名")]),s._v("\nscrapy crawl quotes\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("或在项目中创建一个python程序")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" scrapy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" cmdline\n\ncmdline"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("execute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy crawl txms'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h2",{attrs:{id:"items"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#items"}},[s._v("#")]),s._v(" Items")]),s._v(" "),t("p",[s._v("数据建模")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("定义item文件提前规划好哪些字段需要抓取，防止写错字段名，scrapy会帮我们自动检查错误。")])]),s._v(" "),t("li",[t("p",[s._v("可以清晰自动需要抓取哪些字段")])]),s._v(" "),t("li",[t("p",[s._v("一些特定组件需要Item做支持，如scrapy的imagesPipeline管理类")])])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyspiderItem")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# define the fields for your item here like:")]),s._v("\n    name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 名字")]),s._v("\n    title "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 标题")]),s._v("\n    desc "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 简介")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[t("strong",[s._v("其实是scrapy帮我们创建一个为空的特殊字典，如果没有指定的键时添加时会报错，不会像python字典帮我们自动创建新键。")])]),s._v(" "),t("p",[s._v("需要注意的是：items对象无法直接当做字段来使用，需要强转为字典")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("item "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\njson_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" json"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dumps"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ensure_ascii "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("h2",{attrs:{id:"request"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#request"}},[s._v("#")]),s._v(" Request")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("scrapy")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("http"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Request"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" method"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'GET'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" headers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" body"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cookies"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" meta"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'utf-8'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" priority"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dont_filter"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" errback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Iekrwh/images/md-images/image-20220422220316237.png",alt:"image-20220422220316237"}})]),s._v(" "),t("ul",[t("li",[t("code",[s._v("url（string）")]),s._v(" - 此请求的网址")]),s._v(" "),t("li",[t("code",[s._v("callback（callable）")]),s._v(" - 将使用此请求的响应（一旦下载）作为其第一个参数调用的函数。有关更多信息，请参阅下面的"),t("a",{attrs:{href:"https://doc.scrapy.org/en/1.3/topics/request-response.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("将附加数据传递给回调函数"),t("OutboundLink")],1),s._v("。如果请求没有指定回调，parse()将使用spider的 方法。请注意，如果在处理期间引发异常，则会调用errback。")]),s._v(" "),t("li",[t("code",[s._v("method（string）")]),s._v(" - 此请求的HTTP方法。默认为'GET'。")]),s._v(" "),t("li",[t("code",[s._v("meta（dict）")]),s._v(" - 属性的初始值Request.meta。如果给定，在此参数中传递的dict将被浅复制。包含此请求的任意元数据的字典。此dict对于新请求为空，通常由不同的Scrapy组件（扩展程序，中间件等）填充。因此，此dict中包含的数据取决于您启用的扩展。")]),s._v(" "),t("li",[t("code",[s._v("dont_filter（boolean）")]),s._v(" - 表示此请求不应由调度程序过滤。当您想要多次执行相同的请求时忽略重复过滤器时使用。小心使用它，或者你会进入爬行循环。默认为False。")]),s._v(" "),t("li",[t("code",[s._v("body（str或unicode）")]),s._v(" - 请求体。如果unicode传递了a，那么它被编码为 str使用传递的编码（默认为utf-8）。如果 body没有给出，则存储一个空字符串。不管这个参数的类型，存储的最终值将是一个str（不会是unicode或None）。")]),s._v(" "),t("li",[t("code",[s._v("headers（dict）")]),s._v(" - 这个请求的头。dict值可以是字符串（对于单值标头）或列表（对于多值标头）。如果 None作为值传递，则不会发送HTTP头。")]),s._v(" "),t("li",[t("code",[s._v("cookie（dict或list）")]),s._v(" - 请求cookie。这些可以以两种形式发送。")])]),s._v(" "),t("h2",{attrs:{id:"pipeline管道"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pipeline管道"}},[s._v("#")]),s._v(" pipeline管道")]),s._v(" "),t("ul",[t("li",[s._v("process_item(self,item,spider):\n"),t("ul",[t("li",[s._v("管道类中必须有的函数")]),s._v(" "),t("li",[s._v("实现对item数据的处理")]),s._v(" "),t("li",[s._v("必须return item")])])]),s._v(" "),t("li",[s._v("open_spider(self,spider)  在爬虫开启的时候仅执行一次")]),s._v(" "),t("li",[s._v("close_spider(self,spider)  在爬虫关闭时仅执行一次")])]),s._v(" "),t("p",[s._v("pipeline使用前要在settings中开启")]),s._v(" "),t("div",{staticClass:"language-json line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-json"}},[t("code",[s._v("ITEM_PIPELINES = "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    # 项目名.pipelines.类名\n    'myspider.pipelines.MyspiderPipeline'"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("300")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  # 优先级 小的先执行\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("h2",{attrs:{id:"crawlspider爬虫"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#crawlspider爬虫"}},[s._v("#")]),s._v(" crawlspider爬虫")]),s._v(" "),t("p",[s._v("创建模板型爬虫")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("scrapy genspider "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("t crawl 项目名 域名\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Iekrwh/images/md-images/image-20220426095110146.png",alt:"image-20220426095110146"}})]),s._v(" "),t("p",[s._v("对应的"),t("strong",[s._v("crawlspider就可以实现上述需求，能够匹配满足条件的url地址，组装成Reuqest对象后自动发送给引擎，同时能够指定callback函数")])]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" allow"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deny"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" allow_domains"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deny_domains"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" restrict_xpaths"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tags"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'area'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attrs"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'href'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" canonicalize"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" unique"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" process_value"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deny_extensions"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" restrict_css"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" strip"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" restrict_text"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("CrawlSpider 与 spider 不同的是就在于下一次请求的 url 不需要自己手动解析，而这一点则是通过 LinkExtractors 实现的。")]),s._v(" "),t("ul",[t("li",[s._v("allow：允许的 url。所有满足这个正则表达式的 url 都会被提取")]),s._v(" "),t("li",[s._v("deny：禁止的 url。所有满足这个正则表达式的 url 都不会被提取")]),s._v(" "),t("li",[s._v("allow_domains：允许的域名。只有在这个里面指定的域名的 url 才会被提取")]),s._v(" "),t("li",[s._v("deny_domains：禁止的域名。所有在这个里面指定的域名的 url 都不会被提取")]),s._v(" "),t("li",[s._v("restrict_xpaths：严格的 xpath。和 allow 共同过滤链接")])]),s._v(" "),t("h3",{attrs:{id:"rule"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rule"}},[s._v("#")]),s._v(" Rule")]),s._v(" "),t("p",[s._v("LinkExtractors 需要传递到 Rule 类对象中才能发挥作用。Rule 类为：")]),s._v(" "),t("ol",[t("li",[s._v("rules是一个元组或者是列表，包含的是Rule对象")]),s._v(" "),t("li",[s._v("Rule表示规则，其中包含LinkExtractor,callback和follow等参数")]),s._v(" "),t("li",[s._v("LinkExtractor:连接提取器，可以通过正则或者是xpath来进行url地址的匹配")]),s._v(" "),t("li",[s._v("callback :表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调函数的处理")]),s._v(" "),t("li",[s._v("follow：连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，True表示会，Flase表示不会")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" link_extractor"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callback"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cb_kwargs"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" follow"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n             process_links"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" process_request"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" errback"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("ul",[t("li",[s._v("link_extractor：LinkExtractor 对象，用于定义爬取规则")]),s._v(" "),t("li",[s._v("callback：对于满足该规则的 url 所要执行的回掉函数，类似于之前提到的 scrapy.Request() 中的callback。而 CrawlSpider 使用了 parse 作为回调函数，因此不要覆盖 parse 作为回调函数自己的回调函数")]),s._v(" "),t("li",[s._v("follow：从 response 中提取的链接是否需要跟进")]),s._v(" "),t("li",[s._v("process_links：从 link_extractor 中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接")])]),s._v(" "),t("h2",{attrs:{id:"middlewares中间件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#middlewares中间件"}},[s._v("#")]),s._v(" middlewares中间件")]),s._v(" "),t("h3",{attrs:{id:"下载中间件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#下载中间件"}},[s._v("#")]),s._v(" 下载中间件")]),s._v(" "),t("ul",[t("li",[s._v("process_request(self, request, spider):\n"),t("ul",[t("li",[s._v("每个request通过下载中间件时 该方法被调用")]),s._v(" "),t("li",[s._v("返回Node值： 没有return也是返回Node 该request对象传递给下载器 或通过引擎传递给其他权重低的process_request方法")]),s._v(" "),t("li",[s._v("返回Rsponse对象：不再请求 把response返回给引擎")]),s._v(" "),t("li",[s._v("返回Request对象： 把request对象通过引擎给的调度器 此时将不通过其他权重低的process——request方法")])])])]),s._v(" "),t("h3",{attrs:{id:"爬虫中间件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#爬虫中间件"}},[s._v("#")]),s._v(" 爬虫中间件")]),s._v(" "),t("ul",[t("li",[s._v("process_response(self, request, response, spider):\n"),t("ul",[t("li",[s._v("当下载器完成http请求 传递响应给引擎的时候调用")]),s._v(" "),t("li",[s._v("返回Rsponse对象：通过引擎给爬虫处理或交给权重更低的其他下载中间件的process_response方法")]),s._v(" "),t("li",[s._v("返回Request对象：通过引擎交给调度器继续请求 此时将不通过其他权重低的 process_request方法")])])])]),s._v(" "),t("h2",{attrs:{id:"xpath"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#xpath"}},[s._v("#")]),s._v(" Xpath")]),s._v(" "),t("p",[s._v("1.路径查询 "),t("code",[s._v("//：查找所有子孙节点，不考虑层级关系 / ：找直接子节点")]),s._v("\n2.谓词查询 "),t("code",[s._v('//div[@id] //div[@id="maincontent"]')]),s._v("\n3.属性查询 "),t("code",[s._v("//@class")]),s._v("\n4.模糊查询 "),t("code",[s._v('//div[contains(@id, "he")] //div[starts‐with(@id, "he")]')]),s._v("\n5.内容查询 "),t("code",[s._v("//div/h1/text()")]),s._v("\n6.逻辑运算 "),t("code",[s._v('//div[@id="head" and @class="s_down"] //title | //price')])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("response "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" HtmlResponse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'http://example.com'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" body"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("html"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("encoding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'utf-8'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" HtmlXPathSelector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# selector对象")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#查找所有的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[2]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#查找某一个具体的a标签    取第三个a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[@id]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#查找所有含有id属性的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[@id=\"i1\"]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查找含有id=“i1”的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('\'//a[@href="link.html"][@id="i1"]\'')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查找含有href=‘xxx’并且id=‘xxx’的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[contains(@href, \"link\")]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查找 href属性值中包含有‘link’的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[starts-with(@href, \"link\")]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查找 href属性值以‘link’开始的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[re:test(@id, \"i\\d+\")]'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 正则匹配的用法   匹配id属性的值为数字的a标签")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[re:test(@id, \"i\\d+\")]/text()'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 匹配id属性的值为数字的a标签的文本内容")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[re:test(@id, \"i\\d+\")]/@href'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#匹配id属性的值为数字的a标签的href属性值")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/html/body/ul/li/a/@href'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nhxs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//body/ul/li/a/@href'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hxs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nul_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Selector"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//body/ul/li'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" item "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" ul_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    v "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./a/span'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 或")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# v = item.xpath('a/span')")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 或")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# v = item.xpath('*/a/span')")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br")])]),t("h2",{attrs:{id:"保存数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#保存数据"}},[s._v("#")]),s._v(" 保存数据")]),s._v(" "),t("p",[s._v("scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下：")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("scrapy crawl itcast "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("o teachers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("json\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("json lines格式，默认为Unicode编码")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("scrapy crawl itcast "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("o teachers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jsonl\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("csv 逗号表达式，可用Excel打开")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("scrapy crawl itcast "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("o teachers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("csv\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("xml格式")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("scrapy crawl itcast "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("o teachers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xml\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h2",{attrs:{id:"scrapy-redis"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-redis"}},[s._v("#")]),s._v(" Scrapy_redis")])])}),[],!1,null,null,null);t.default=e.exports}}]);